{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering Pipeline v2\n",
        "\n",
        "Produces `train_features.csv`, `test_features.csv`, and `holdout_features.csv` in `data/`.\n",
        "\n",
        "### Improvements over v1\n",
        "\n",
        "1. **Bug fix**: patient features are now properly joined to time-series rows (v1 had a missing merge)\n",
        "2. **Missingness as signal**: `bmi_missing`, `pain_score_missing`, `reason_missing` indicators — EDA showed missingness itself correlates with outcome\n",
        "3. **Comorbidity features**: parsed from `previous_medical_history` free-text — hypertension, diabetes, kidney disease, cardiac conditions, anemia, obesity. Comorbidity count showed a monotonic relationship with label 3 (6.6% at 0 → 29.1% at 6 comorbidities)\n",
        "4. **Encounter description**: one-hot encoded — obstetric encounters had 0% label 3 vs 23% for ED patient visits\n",
        "5. **Reason-for-visit risk tier**: grouped into high/medium/low risk — myocardial infarction (25%), stroke (28%), gunshot (28%) vs normal pregnancy (0%)\n",
        "6. **Age group flags**: `is_elderly` (≥65) and `is_child` (<18) — label 3 rate jumps from 3.6% in age 19–35 to 22.3% in 80+\n",
        "7. **Marital status**: included now (p=0.000008 chi-square vs outcome)\n",
        "8. **Medication flags**: on cardiac meds (metoprolol, nitroglycerin) = 29% label 3 vs 9% baseline\n",
        "\n",
        "### EDA-driven rationale for dropping features\n",
        "\n",
        "| Column | Missing % | Decision | Reason |\n",
        "|---|---|---|---|\n",
        "| `known_allergies` | 85% | **Drop** | Too sparse, no significant association (p=0.45) |\n",
        "| `previous_medications` | 67% | **Drop** | No association with outcome (p=0.70) |\n",
        "| `bmi` | 65% | **Keep + missingness flag** | Marginal signal (p=0.07), but missingness pattern informative |\n",
        "| `pain_score` | 64% | **Keep + missingness flag** | Similar: value weak, missingness informative |\n",
        "| `current_medications` | 59% | **Keep as flags** | Cardiac med keywords strongly predict deterioration |\n",
        "| `race` | 0% | **Keep (OHE)** | No significant signal (p=0.63) but kept for completeness |\n",
        "| `ethnicity` | 0% | **Keep (OHE)** | No signal (p=0.92) but zero cost |\n",
        "\n",
        "> **Leakage guard**: all scalers and encoders are **fit on train encounters only** then applied to test and holdout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "from utils.features import add_lag_features_with_imputation, add_spectral_features, build_patient_features, join_patient_features\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "\n",
        "VITAL_COLS = [\n",
        "    'heart_rate', 'systolic_bp', 'diastolic_bp',\n",
        "    'respiratory_rate', 'oxygen_saturation'\n",
        "]\n",
        "N_LAGS = 12  # 12 lags × 5 s cadence = 60-second lookback window\n",
        "N_LAGS_SPECTRAL = 36  # 180s window for signal processing (see spectral_features_eda.ipynb)\n",
        "SAMPLE_RATE_HZ = 0.2  # 5s cadence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train   : (2109600, 8)  |  encounters: 2,930\n",
            "test    : (451440, 8)  |  encounters: 627\n",
            "holdout : (452880, 7)  |  encounters: 629\n",
            "\n",
            "patients: (4186, 17)\n",
            "\n",
            "Vital missing values (train raw):\n",
            "heart_rate           42252\n",
            "systolic_bp          42197\n",
            "diastolic_bp         42320\n",
            "respiratory_rate     42278\n",
            "oxygen_saturation    42618\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_raw   = pd.read_csv(DATA_DIR / 'train_data.csv',   parse_dates=['timestamp'])\n",
        "test_raw    = pd.read_csv(DATA_DIR / 'test_data.csv',    parse_dates=['timestamp'])\n",
        "holdout_raw = pd.read_csv(DATA_DIR / 'holdout_data.csv', parse_dates=['timestamp'])\n",
        "patients    = pd.read_csv(DATA_DIR / 'patients.csv')\n",
        "\n",
        "for name, df in [('train', train_raw), ('test', test_raw), ('holdout', holdout_raw)]:\n",
        "    print(f\"{name:8s}: {df.shape}  |  encounters: {df['encounter_id'].nunique():,}\")\n",
        "\n",
        "print(f\"\\npatients: {patients.shape}\")\n",
        "print(f\"\\nVital missing values (train raw):\")\n",
        "print(train_raw[VITAL_COLS].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Vital Sign Imputation\n",
        "\n",
        "**Strategy** (applied per encounter, in order):\n",
        "1. **Neighbour interpolation** — fill with the mean of the adjacent timestamps (before & after)\n",
        "2. **Encounter-median fallback** — for remaining gaps (start/end of sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vital imputation complete — no missing values remain.\n"
          ]
        }
      ],
      "source": [
        "def impute_vitals(df: pd.DataFrame, vital_cols: list) -> pd.DataFrame:\n",
        "    \"\"\"Impute missing vital signs within each encounter.\"\"\"\n",
        "    df = df.sort_values(['encounter_id', 'timestamp']).reset_index(drop=True)\n",
        "    out = df.copy()\n",
        "    for col in vital_cols:\n",
        "        prev = out.groupby('encounter_id')[col].shift(1)\n",
        "        nxt  = out.groupby('encounter_id')[col].shift(-1)\n",
        "        neighbour_mean = pd.concat([prev, nxt], axis=1).mean(axis=1)\n",
        "        out[col] = out[col].fillna(neighbour_mean)\n",
        "        out[col] = out.groupby('encounter_id')[col].transform(\n",
        "            lambda x: x.fillna(x.median())\n",
        "        )\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = impute_vitals(train_raw,   VITAL_COLS)\n",
        "test    = impute_vitals(test_raw,    VITAL_COLS)\n",
        "holdout = impute_vitals(holdout_raw, VITAL_COLS)\n",
        "\n",
        "for name, df in [('train', train), ('test', test), ('holdout', holdout)]:\n",
        "    assert df[VITAL_COLS].isna().sum().sum() == 0, f\"{name}: vitals still have NaNs\"\n",
        "print(\"Vital imputation complete — no missing values remain.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Lag Features\n",
        "\n",
        "Each vital gets 12 lags (lag1 = 5s ago … lag12 = 60s ago), within each encounter.\n",
        "Leading NaN rows filled with encounter-median."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lag features added: 60 columns (5 vitals × 12 lags) — 14.2s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "t0 = time.perf_counter()\n",
        "train, lag_cols   = add_lag_features_with_imputation(train,   VITAL_COLS, N_LAGS)\n",
        "test, _           = add_lag_features_with_imputation(test,    VITAL_COLS, N_LAGS)\n",
        "holdout, _        = add_lag_features_with_imputation(holdout, VITAL_COLS, N_LAGS)\n",
        "elapsed = time.perf_counter() - t0\n",
        "\n",
        "for name, df in [('train', train), ('test', test), ('holdout', holdout)]:\n",
        "    assert df[lag_cols].isna().sum().sum() == 0, f\"{name}: lag cols still have NaNs\"\n",
        "print(f\"Lag features added: {len(lag_cols)} columns ({len(VITAL_COLS)} vitals × {N_LAGS} lags) — {elapsed:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Derivative Features\n",
        "\n",
        "| Feature | Formula | Clinical meaning |\n",
        "|---|---|---|\n",
        "| `{v}_delta` | current − lag12 | 60-second trend |\n",
        "| `{v}_delta_1s` | current − lag1 | Immediate velocity (5s) |\n",
        "| `{v}_accel` | current − 2·lag1 + lag2 | Acceleration |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Derivative features added: 15 columns\n"
          ]
        }
      ],
      "source": [
        "def add_derivative_features(df: pd.DataFrame, vital_cols: list, n_lags: int) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    for v in vital_cols:\n",
        "        out[f'{v}_delta']    = out[v] - out[f'{v}_lag{n_lags}']\n",
        "        out[f'{v}_delta_1s'] = out[v] - out[f'{v}_lag1']\n",
        "        out[f'{v}_accel']    = out[v] - 2 * out[f'{v}_lag1'] + out[f'{v}_lag2']\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = add_derivative_features(train,   VITAL_COLS, N_LAGS)\n",
        "test    = add_derivative_features(test,    VITAL_COLS, N_LAGS)\n",
        "holdout = add_derivative_features(holdout, VITAL_COLS, N_LAGS)\n",
        "\n",
        "deriv_cols = [f'{v}{s}' for v in VITAL_COLS for s in ('_delta', '_delta_1s', '_accel')]\n",
        "print(f\"Derivative features added: {len(deriv_cols)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Rolling Window Statistics\n",
        "\n",
        "mean, std, min, max over the 13-value window [lag12 … current]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rolling stats added: 20 columns\n"
          ]
        }
      ],
      "source": [
        "def add_rolling_stats(df: pd.DataFrame, vital_cols: list, n_lags: int) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    for v in vital_cols:\n",
        "        window_cols = [f'{v}_lag{i}' for i in range(n_lags, 0, -1)] + [v]\n",
        "        window = out[window_cols]\n",
        "        out[f'{v}_mean'] = window.mean(axis=1)\n",
        "        out[f'{v}_std']  = window.std(axis=1, ddof=0)\n",
        "        out[f'{v}_min']  = window.min(axis=1)\n",
        "        out[f'{v}_max']  = window.max(axis=1)\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = add_rolling_stats(train,   VITAL_COLS, N_LAGS)\n",
        "test    = add_rolling_stats(test,    VITAL_COLS, N_LAGS)\n",
        "holdout = add_rolling_stats(holdout, VITAL_COLS, N_LAGS)\n",
        "\n",
        "rolling_cols = [f'{v}{s}' for v in VITAL_COLS for s in ('_mean', '_std', '_min', '_max')]\n",
        "print(f\"Rolling stats added: {len(rolling_cols)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Derived Vital Signs\n",
        "\n",
        "| Feature | Formula | Clinical meaning |\n",
        "|---|---|---|\n",
        "| `pulse_pressure` | SBP − DBP | Vasodilation (widened) vs poor cardiac output (narrowed) |\n",
        "| `map` | (SBP + 2·DBP) / 3 | MAP < 65 = hypotension/shock |\n",
        "| `pulse_pressure_delta` | PP − PP_lag12 | PP trajectory over 60s |\n",
        "| `map_delta` | MAP − MAP_lag12 | MAP trajectory over 60s |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Derived vital features added: 4 columns\n"
          ]
        }
      ],
      "source": [
        "def add_derived_vitals(df: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['pulse_pressure'] = out['systolic_bp'] - out['diastolic_bp']\n",
        "    out['map']            = (out['systolic_bp'] + 2 * out['diastolic_bp']) / 3\n",
        "\n",
        "    pp_lagN  = out[f'systolic_bp_lag{n_lags}'] - out[f'diastolic_bp_lag{n_lags}']\n",
        "    map_lagN = (out[f'systolic_bp_lag{n_lags}'] + 2 * out[f'diastolic_bp_lag{n_lags}']) / 3\n",
        "\n",
        "    out['pulse_pressure_delta'] = out['pulse_pressure'] - pp_lagN\n",
        "    out['map_delta']            = out['map'] - map_lagN\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = add_derived_vitals(train,   N_LAGS)\n",
        "test    = add_derived_vitals(test,    N_LAGS)\n",
        "holdout = add_derived_vitals(holdout, N_LAGS)\n",
        "\n",
        "derived_cols = ['pulse_pressure', 'map', 'pulse_pressure_delta', 'map_delta']\n",
        "print(f\"Derived vital features added: {len(derived_cols)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Temporal Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temporal features added: 5 columns\n"
          ]
        }
      ],
      "source": [
        "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    enc_start = out.groupby('encounter_id')['timestamp'].transform('min')\n",
        "    out['minutes_into_encounter'] = (out['timestamp'] - enc_start).dt.total_seconds() / 60\n",
        "\n",
        "    hour = out['timestamp'].dt.hour\n",
        "    out['hour_sin'] = np.sin(2 * np.pi * hour / 24)\n",
        "    out['hour_cos'] = np.cos(2 * np.pi * hour / 24)\n",
        "\n",
        "    dow = out['timestamp'].dt.dayofweek\n",
        "    out['dow_sin'] = np.sin(2 * np.pi * dow / 7)\n",
        "    out['dow_cos'] = np.cos(2 * np.pi * dow / 7)\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = add_temporal_features(train)\n",
        "test    = add_temporal_features(test)\n",
        "holdout = add_temporal_features(holdout)\n",
        "\n",
        "temporal_cols = ['minutes_into_encounter', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
        "print(f\"Temporal features added: {len(temporal_cols)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Encounter Prior Label Features\n",
        "\n",
        "All use `shift(1)` — current row's label never predicts itself.\n",
        "Holdout (no labels) gets zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  No 'label' column — prior label features set to 0 (holdout mode).\n",
            "Prior label features added: ['prior_label', 'max_label_last_60s', 'max_label_encounter', 'ever_deteriorated']\n",
            "  Sanity check passed: first row of each encounter has prior_label=0\n"
          ]
        }
      ],
      "source": [
        "PRIOR_LABEL_COLS = ['prior_label', 'max_label_last_60s', 'max_label_encounter', 'ever_deteriorated']\n",
        "\n",
        "\n",
        "def add_encounter_prior_label_features(df: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = df.sort_values(['encounter_id', 'timestamp']).reset_index(drop=True).copy()\n",
        "\n",
        "    if 'label' not in df.columns:\n",
        "        for col in PRIOR_LABEL_COLS:\n",
        "            out[col] = 0.0\n",
        "        print(\"  No 'label' column — prior label features set to 0 (holdout mode).\")\n",
        "        return out\n",
        "\n",
        "    out['prior_label'] = out.groupby('encounter_id')['label'].shift(1).fillna(0)\n",
        "\n",
        "    out['max_label_last_60s'] = (\n",
        "        out.groupby('encounter_id')['label']\n",
        "        .transform(lambda x: x.shift(1).rolling(n_lags, min_periods=1).max())\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    out['max_label_encounter'] = (\n",
        "        out.groupby('encounter_id')['label']\n",
        "        .transform(lambda x: x.shift(1).expanding().max())\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    out['ever_deteriorated'] = (out['max_label_encounter'] > 0).astype(float)\n",
        "    return out\n",
        "\n",
        "\n",
        "train   = add_encounter_prior_label_features(train,   N_LAGS)\n",
        "test    = add_encounter_prior_label_features(test,    N_LAGS)\n",
        "holdout = add_encounter_prior_label_features(holdout, N_LAGS)\n",
        "\n",
        "print(f\"Prior label features added: {PRIOR_LABEL_COLS}\")\n",
        "if 'label' in train.columns:\n",
        "    first_rows = train.groupby('encounter_id').head(1)\n",
        "    assert (first_rows['prior_label'] == 0).all()\n",
        "    print(\"  Sanity check passed: first row of each encounter has prior_label=0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Patient Features (v2 — EDA-informed)\n",
        "\n",
        "### Key EDA findings that shaped this section\n",
        "\n",
        "**Strong predictors** (p < 0.001 via t-test or chi-square):\n",
        "- `age`: mean 46.5 (no label 3) vs 63.7 (label 3), t=-12.33\n",
        "- `gender`: M = 16.2% label 3, F = 5.6%\n",
        "- `encounter_description`: obstetric = 0% label 3, ED patient visit = 23.1%\n",
        "- `reason_for_visit`: MI = 25.3%, stroke = 27.8%, normal pregnancy = 0%\n",
        "- `marital_status`: chi2=29.04, p=0.000008\n",
        "- Comorbidity count: 6.6% at 0 → 29.1% at 6 comorbidities\n",
        "- Cardiac medications (metoprolol, nitroglycerin): 29% label 3 vs 9% baseline\n",
        "\n",
        "**Missingness is informative**:\n",
        "- `reason_for_visit` missing → 20% label 3 vs 9.2% when present (older, sicker patients)\n",
        "- `current_medications` present → 13.3% label 3 vs 8.7% (patients on meds are sicker)\n",
        "- `previous_medical_history` present → 11.8% vs 7.0%\n",
        "\n",
        "**Dropped** (not worth the noise):\n",
        "- `known_allergies`: 85% missing, p=0.45\n",
        "- `previous_medications`: 67% missing, p=0.70\n",
        "- `date_of_birth`: redundant with age\n",
        "- `patient_name`: synthetic identifier\n",
        "- `encounter_class`: single value (emergency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10a. Build and join patient features (utils.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patient features: 45 columns\n",
            "  train   : (2109600, 161)  patient_feature_NaNs=0\n",
            "  test    : (451440, 161)  patient_feature_NaNs=0\n",
            "  holdout : (452880, 160)  patient_feature_NaNs=0\n"
          ]
        }
      ],
      "source": [
        "train_encounter_ids = set(train['encounter_id'].unique())\n",
        "patients, patient_feature_cols = build_patient_features(patients, train_encounter_ids)\n",
        "\n",
        "train   = join_patient_features(train,   patients, patient_feature_cols)\n",
        "test    = join_patient_features(test,    patients, patient_feature_cols)\n",
        "holdout = join_patient_features(holdout, patients, patient_feature_cols)\n",
        "\n",
        "print(f\"Patient features: {len(patient_feature_cols)} columns\")\n",
        "for name, df in [('train', train), ('test', test), ('holdout', holdout)]:\n",
        "    n_missing = df[patient_feature_cols].isna().sum().sum()\n",
        "    print(f\"  {name:8s}: {df.shape}  patient_feature_NaNs={n_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Final Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train   : shape=(2109600, 161)  missing_feature_values=0\n",
            "test    : shape=(451440, 161)  missing_feature_values=0\n",
            "holdout : shape=(452880, 160)  missing_feature_values=0\n"
          ]
        }
      ],
      "source": [
        "feature_cols = (\n",
        "    VITAL_COLS\n",
        "    + lag_cols\n",
        "    + deriv_cols\n",
        "    + rolling_cols\n",
        "    + derived_cols\n",
        "    + temporal_cols\n",
        "    + PRIOR_LABEL_COLS\n",
        "    + patient_feature_cols\n",
        ")\n",
        "\n",
        "for name, df in [('train', train), ('test', test), ('holdout', holdout)]:\n",
        "    n_missing = df[feature_cols].isna().sum().sum()\n",
        "    assert n_missing == 0, f\"{name}: {n_missing} NaNs remain in feature columns\"\n",
        "    print(f\"{name:8s}: shape={df.shape}  missing_feature_values={n_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save to data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv(  DATA_DIR / 'train_features.csv',   index=False)\n",
        "test.to_csv(   DATA_DIR / 'test_features.csv',    index=False)\n",
        "holdout.to_csv(DATA_DIR / 'holdout_features.csv', index=False)\n",
        "\n",
        "for name, path in [\n",
        "    ('train',   DATA_DIR / 'train_features.csv'),\n",
        "    ('test',    DATA_DIR / 'test_features.csv'),\n",
        "    ('holdout', DATA_DIR / 'holdout_features.csv'),\n",
        "]:\n",
        "    size_mb = path.stat().st_size / 1e6\n",
        "    print(f\"Saved {name:8s} -> {path}  ({size_mb:.1f} MB)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
