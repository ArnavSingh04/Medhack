{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering Pipeline v2\n",
        "\n",
        "Produces `train_features.parquet`, `test_features.parquet`, and `holdout_features.parquet` in `data/`. Uses `FeatureEngineer` from `utils.features` for the full pipeline.\n",
        "\n",
        "### Improvements over v1\n",
        "\n",
        "1. **Bug fix**: patient features are now properly joined to time-series rows (v1 had a missing merge)\n",
        "2. **Missingness as signal**: `bmi_missing`, `pain_score_missing`, `reason_missing` indicators — EDA showed missingness itself correlates with outcome\n",
        "3. **Comorbidity features**: parsed from `previous_medical_history` free-text — hypertension, diabetes, kidney disease, cardiac conditions, anemia, obesity. Comorbidity count showed a monotonic relationship with label 3 (6.6% at 0 → 29.1% at 6 comorbidities)\n",
        "4. **Encounter description**: one-hot encoded — obstetric encounters had 0% label 3 vs 23% for ED patient visits\n",
        "5. **Reason-for-visit risk tier**: grouped into high/medium/low risk — myocardial infarction (25%), stroke (28%), gunshot (28%) vs normal pregnancy (0%)\n",
        "6. **Age group flags**: `is_elderly` (≥65) and `is_child` (<18) — label 3 rate jumps from 3.6% in age 19–35 to 22.3% in 80+\n",
        "7. **Marital status**: included now (p=0.000008 chi-square vs outcome)\n",
        "8. **Medication flags**: on cardiac meds (metoprolol, nitroglycerin) = 29% label 3 vs 9% baseline\n",
        "\n",
        "### EDA-driven rationale for dropping features\n",
        "\n",
        "| Column | Missing % | Decision | Reason |\n",
        "|---|---|---|---|\n",
        "| `known_allergies` | 85% | **Drop** | Too sparse, no significant association (p=0.45) |\n",
        "| `previous_medications` | 67% | **Drop** | No association with outcome (p=0.70) |\n",
        "| `bmi` | 65% | **Keep + missingness flag** | Marginal signal (p=0.07), but missingness pattern informative |\n",
        "| `pain_score` | 64% | **Keep + missingness flag** | Similar: value weak, missingness informative |\n",
        "| `current_medications` | 59% | **Keep as flags** | Cardiac med keywords strongly predict deterioration |\n",
        "| `race` | 0% | **Keep (OHE)** | No significant signal (p=0.63) but kept for completeness |\n",
        "| `ethnicity` | 0% | **Keep (OHE)** | No signal (p=0.92) but zero cost |\n",
        "\n",
        "> **Leakage guard**: all scalers and encoders are **fit on train encounters only** then applied to test and holdout.\n",
        "\n",
        "### medhack-frontiers improvements (added)\n",
        "\n",
        "9. **Shock index & HR:RR ratio** — hemodynamic instability markers (shock_index = HR/SBP, hr_rr_ratio = HR/RR)\n",
        "10. **Multi-scale rolling** — 4 windows (6, 12, 24, 60 steps ≈ 30s–5m) for mean/std/min/max per vital\n",
        "11. **ECG features** — basic stats + FFT (dom_freq, LF/HF power, LF/HF ratio, spectral entropy), hr_ecg_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure notebooks/ is on path (Jupyter cwd is usually the notebook directory)\n",
        "_nb_dir = Path.cwd()\n",
        "if str(_nb_dir) not in sys.path:\n",
        "    sys.path.insert(0, str(_nb_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load FeatureEngineer directly from utils/features.py (avoids utils package init issues)\n",
        "_nb_dir = Path.cwd()\n",
        "_spec = importlib.util.spec_from_file_location(\n",
        "    \"utils.features\",\n",
        "    _nb_dir / \"utils\" / \"features.py\",\n",
        ")\n",
        "_feat = importlib.util.module_from_spec(_spec)\n",
        "_spec.loader.exec_module(_feat)\n",
        "FeatureEngineer = _feat.FeatureEngineer\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "\n",
        "engineer = FeatureEngineer(\n",
        "    n_lags=12,\n",
        "    rolling_windows=[6, 12, 24, 60],\n",
        "    data_dir=DATA_DIR,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Raw Data & Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train   : (2109600, 8)  |  encounters: 2,930\n",
            "test    : (451440, 8)  |  encounters: 627\n",
            "holdout : (452880, 7)  |  encounters: 629\n",
            "\n",
            "patients: (4186, 17)\n",
            "\n",
            "Feature pipeline complete: 256 columns\n"
          ]
        }
      ],
      "source": [
        "train_raw = pd.read_csv(DATA_DIR / \"train_data.csv\", parse_dates=[\"timestamp\"])\n",
        "test_raw = pd.read_csv(DATA_DIR / \"test_data.csv\", parse_dates=[\"timestamp\"])\n",
        "holdout_raw = pd.read_csv(DATA_DIR / \"holdout_data.csv\", parse_dates=[\"timestamp\"])\n",
        "patients = pd.read_csv(DATA_DIR / \"patients.csv\")\n",
        "\n",
        "for name, df in [(\"train\", train_raw), (\"test\", test_raw), (\"holdout\", holdout_raw)]:\n",
        "    print(f\"{name:8s}: {df.shape}  |  encounters: {df['encounter_id'].nunique():,}\")\n",
        "print(f\"\\npatients: {patients.shape}\")\n",
        "\n",
        "train, test, holdout, feature_cols = engineer.transform(\n",
        "    train_raw, test_raw, holdout_raw, patients\n",
        ")\n",
        "print(f\"\\nFeature pipeline complete: {len(feature_cols)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train   : shape=(2109600, 259)  missing_feature_values=0\n",
            "test    : shape=(451440, 259)  missing_feature_values=0\n",
            "holdout : shape=(452880, 258)  missing_feature_values=0\n"
          ]
        }
      ],
      "source": [
        "for name, df in [(\"train\", train), (\"test\", test), (\"holdout\", holdout)]:\n",
        "    n_missing = df[feature_cols].isna().sum().sum()\n",
        "    assert n_missing == 0, f\"{name}: {n_missing} NaNs in features\"\n",
        "    print(f\"{name:8s}: shape={df.shape}  missing_feature_values={n_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use fastparquet to avoid pyarrow 23.x compatibility issue with pandas\n",
        "train.to_parquet(DATA_DIR / \"train_features.parquet\", index=False, engine=\"fastparquet\")\n",
        "test.to_parquet(DATA_DIR / \"test_features.parquet\", index=False, engine=\"fastparquet\")\n",
        "holdout.to_parquet(DATA_DIR / \"holdout_features.parquet\", index=False, engine=\"fastparquet\")\n",
        "print(\"Saved train_features.parquet, test_features.parquet, holdout_features.parquet\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
