{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LightGBM Hyperparameter Tuning with Optuna\n",
        "\n",
        "**MedHack Frontiers** — Optuna tunes LightGBM on precomputed features.\n",
        "\n",
        "## Setup (Google Colab)\n",
        "1. Upload these files to a folder in Google Drive (e.g. `MyDrive/medhack-frontiers/`):\n",
        "   - `train_features.parquet`, `test_features.parquet`, `holdout_features.parquet`\n",
        "   - `train_data.csv`, `test_data.csv` (required for FAR: encounter-level false alarm rate)\n",
        "   - `sample_submission.csv` (optional, for validation)\n",
        "2. Update `DRIVE_DATA_DIR` below to match your folder path.\n",
        "3. Run all cells.\n",
        "\n",
        "**Note:** Train and test are loaded separately (no concat) to avoid RAM issues. Multi-objective tuning: maximize Mean Macro-AUPRC, minimize False Alarm Rate (FAR = % of healthy encounters with ≥1 alarm at prob > 0.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only exeecute cell below for colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: /usr/local/bin/pip: bad interpreter: /usr/local/opt/python@3.11/bin/python3.11: no such file or directory\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     18\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m     22\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m DRIVE_DATA_DIR = \u001b[33m'\u001b[39m\u001b[33m/content/drive/MyDrive/MedHack 2026/data\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Update if your folder is elsewhere\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!pip install -q lightgbm scikit-learn optuna pandas pyarrow \"optuna-integration[lightgbm]\"\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_DATA_DIR = '/content/drive/MyDrive/MedHack 2026/data'  # Update if your folder is elsewhere\n",
        "\n",
        "ZIP_PATH = '/content/drive/MyDrive/MedHack 2026/data/Archive.zip'\n",
        "!unzip -q \"{ZIP_PATH}\" -d /content/dataset\n",
        "!ls /content/dataset/data\n",
        "\n",
        "TRAIN_PATH = '/content/dataset/data/train_features.parquet'\n",
        "TEST_PATH = '/content/dataset/data/test_features.parquet'\n",
        "HOLDOUT_PATH = '/content/dataset/data/holdout_features.parquet'\n",
        "\n",
        "print(\"Loading features from Google Drive...\")\n",
        "train = pd.read_parquet(TRAIN_PATH)\n",
        "test = pd.read_parquet(TEST_PATH)\n",
        "holdout = pd.read_parquet(HOLDOUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from sklearn.metrics import f1_score, classification_report, average_precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading features locally...\n"
          ]
        }
      ],
      "source": [
        "# Load parquet features \n",
        "DATA_DIR = Path(\"../data\")\n",
        "print(\"Loading features locally...\")\n",
        "train = pd.read_parquet(DATA_DIR / \"train_features.parquet\")\n",
        "test = pd.read_parquet(DATA_DIR / \"test_features.parquet\")\n",
        "holdout = pd.read_parquet(DATA_DIR / \"holdout_features.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Use all features (exclude label)\n",
        "EXCLUDE_COLS = [\"label\"]\n",
        "\n",
        "\n",
        "def macro_fpr(y_true, y_pred, n_classes=4):\n",
        "    \"\"\"Macro average false positive rate (one-vs-rest per class).\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(n_classes))\n",
        "    fprs = []\n",
        "    for i in range(n_classes):\n",
        "        fp = cm[:, i].sum() - cm[i, i]\n",
        "        n_neg = cm.sum() - cm[i, :].sum()\n",
        "        fprs.append(fp / n_neg if n_neg > 0 else 0)\n",
        "    return np.mean(fprs)\n",
        "\n",
        "\n",
        "def false_alarm_rate(y_true, y_prob, encounter_ids, threshold=0.5):\n",
        "    \"\"\"\n",
        "    FAR = % of all-negative (healthy) encounters where predicted prob for\n",
        "    deterioration (classes 1,2,3) crosses threshold at least once.\n",
        "    \"\"\"\n",
        "    # Prob of any positive/deterioration class (1, 2, 3)\n",
        "    prob_positive = y_prob[:, 1:].sum(axis=1)\n",
        "    df = pd.DataFrame({\"encounter_id\": encounter_ids, \"label\": y_true, \"prob_pos\": prob_positive})\n",
        "    # Healthy encounters: all labels are 0\n",
        "    healthy = df.groupby(\"encounter_id\").agg({\"label\": \"max\", \"prob_pos\": \"max\"}).reset_index()\n",
        "    healthy_encounters = healthy[healthy[\"label\"] == 0]\n",
        "    n_healthy = len(healthy_encounters)\n",
        "    if n_healthy == 0:\n",
        "        return 0.0\n",
        "    n_false_alarms = (healthy_encounters[\"prob_pos\"] >= threshold).sum()\n",
        "    return n_false_alarms / n_healthy\n",
        "\n",
        "\n",
        "print(\"Imports OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped non-numeric columns: {'encounter_id'}\n",
            "Train: (2109600, 257), Test: (451440, 257), Holdout: (452880, 258)\n",
            "Features used: 257\n",
            "\n",
            "Train label distribution:\n",
            "label\n",
            "0    1548998\n",
            "1     359553\n",
            "2     139107\n",
            "3      61942\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class weights: {0: 0.34047816717645857, 1: 1.4668213031180382, 2: 11.37397830447066, 3: 17.028833424816764}\n",
            "Loading encounter_ids for FAR...\n",
            "\n",
            "Phase 1 tune sample: 211,680 rows (10% of train)\n",
            "Phase 2: full train data\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "feature_cols = [c for c in train.columns if c not in EXCLUDE_COLS]\n",
        "X_train = train[feature_cols].copy()\n",
        "y_train = train[\"label\"].astype(int)\n",
        "X_test = test[feature_cols].copy()\n",
        "y_test = test[\"label\"].astype(int)\n",
        "\n",
        "# LightGBM requires numeric features only - convert datetime, drop string/object\n",
        "def ensure_numeric_features(df, cols):\n",
        "    \"\"\"Convert datetime to numeric, drop non-numeric columns. Returns (df, updated_cols).\"\"\"\n",
        "    keep_cols = []\n",
        "    for col in cols:\n",
        "        dtype = df[col].dtype\n",
        "        if pd.api.types.is_numeric_dtype(dtype):\n",
        "            keep_cols.append(col)\n",
        "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
        "            keep_cols.append(col)\n",
        "            df[col] = df[col].astype(\"int64\")  # Unix timestamp\n",
        "        # else: drop string/object columns\n",
        "    dropped = set(cols) - set(keep_cols)\n",
        "    if dropped:\n",
        "        print(f\"Dropped non-numeric columns: {dropped}\")\n",
        "    return df[keep_cols], keep_cols\n",
        "\n",
        "X_train, feature_cols = ensure_numeric_features(X_train, feature_cols)\n",
        "X_test = X_test[feature_cols].copy()\n",
        "# Convert any datetime cols in X_test (should match X_train)\n",
        "for col in feature_cols:\n",
        "    if pd.api.types.is_datetime64_any_dtype(X_test[col].dtype):\n",
        "        X_test[col] = X_test[col].astype(\"int64\")\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Test: {X_test.shape}, Holdout: {holdout.shape}\")\n",
        "print(f\"Features used: {len(feature_cols)}\")\n",
        "print(f\"\\nTrain label distribution:\\n{y_train.value_counts().sort_index()}\")\n",
        "\n",
        "# Class weights from train (same as medhack_pipeline)\n",
        "class_counts = y_train.value_counts().sort_index()\n",
        "total = len(y_train)\n",
        "class_weights = {c: total / (len(class_counts) * count) for c, count in class_counts.items()}\n",
        "class_weights[2] = class_weights[2] * 3.0\n",
        "class_weights[3] = class_weights[3] * 2.0\n",
        "sample_weights = y_train.map(class_weights).values\n",
        "print(f\"\\nClass weights: {class_weights}\")\n",
        "\n",
        "# Load encounter_ids for FAR (test set only)\n",
        "print(\"Loading encounter_ids for FAR...\")\n",
        "test_encounter_ids = pd.read_csv(DATA_DIR / \"test_data.csv\", usecols=[\"encounter_id\"])[\"encounter_id\"]\n",
        "assert len(test_encounter_ids) == len(X_test), f\"Row mismatch: {len(test_encounter_ids)} vs {len(X_test)}\"\n",
        "\n",
        "# Optuna threshold for FAR\n",
        "FAR_THRESHOLD = 0.5\n",
        "\n",
        "# --- Two-phase tuning: stratified sampling for Phase 1 ---\n",
        "SAMPLE_FRAC_PHASE1 = 0.1   # 10% of encounters for fast Phase 1 exploration\n",
        "N_TOP_PHASE1 = 5           # Top configs to carry to Phase 2\n",
        "PHASE2_FULL_DATA = True    # Phase 2 uses full train (False = 50% sample)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Encounter-level stratified sample (preserves class distribution per encounter)\n",
        "encounter_labels = train.groupby(\"encounter_id\")[\"label\"].max()\n",
        "encounters_phase1 = encounter_labels.groupby(encounter_labels, group_keys=False).apply(\n",
        "    lambda x: x.sample(frac=SAMPLE_FRAC_PHASE1, random_state=RANDOM_STATE)\n",
        ").index\n",
        "phase1_mask = train[\"encounter_id\"].isin(encounters_phase1)\n",
        "\n",
        "X_tune = X_train[phase1_mask].copy()\n",
        "y_tune = y_train[phase1_mask].values\n",
        "w_tune = sample_weights[phase1_mask.values]\n",
        "\n",
        "# Phase 2 sample (if not full data): encounter-level stratified 50%\n",
        "if not PHASE2_FULL_DATA:\n",
        "    encounters_phase2 = encounter_labels.groupby(encounter_labels, group_keys=False).apply(\n",
        "        lambda x: x.sample(frac=0.5, random_state=RANDOM_STATE + 1)\n",
        "    ).index\n",
        "    phase2_mask = train[\"encounter_id\"].isin(encounters_phase2)\n",
        "else:\n",
        "    phase2_mask = None  # Use all rows\n",
        "\n",
        "print(f\"\\nPhase 1 tune sample: {X_tune.shape[0]:,} rows ({SAMPLE_FRAC_PHASE1*100:.0f}% of train)\")\n",
        "print(f\"Phase 2: {'full' if PHASE2_FULL_DATA else '50%'} train data\")\n",
        "\n",
        "del train, test\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optuna Two-Phase Multi-Objective Tuning\n",
        "\n",
        "**Phase 1:** Fast exploration on 10% stratified sample with MedianPruner + LightGBMPruningCallback.  \n",
        "**Phase 2:** Top configs re-evaluated on full train data.\n",
        "\n",
        "**Objectives:** (A) Maximize Mean Macro-AUPRC, (B) Minimize FAR — % of healthy encounters where prob(deterioration) ≥ 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, X_tr, y_tr, w_tr):\n",
        "    \"\"\"Objective for Phase 1: trains on (X_tr, y_tr, w_tr), evaluates on X_test/y_test.\"\"\"\n",
        "    params = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"num_class\": 4,\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"verbosity\": -1,\n",
        "        \"n_jobs\": -1,\n",
        "        \"seed\": 42,\n",
        "        # Tunable hyperparameters\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 63, 511),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.3, 0.8),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 0.9),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 3, 10),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 50, 300),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0, log=True),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 12),\n",
        "    }\n",
        "\n",
        "    dtrain = lgb.Dataset(X_tr, label=y_tr, weight=w_tr)\n",
        "    dval = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
        "\n",
        "    # LightGBMPruningCallback does not support multi-objective studies (it needs study.direction).\n",
        "    # Use only early_stopping; LightGBM will still prune within each trial based on valid loss.\n",
        "    model = lgb.train(\n",
        "        params, dtrain,\n",
        "        num_boost_round=1500,  # Slightly fewer for Phase 1; early stopping handles rest\n",
        "        valid_sets=[dval],\n",
        "        valid_names=[\"valid\"],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(50, verbose=False),\n",
        "            lgb.log_evaluation(0),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    y_prob = model.predict(X_test)\n",
        "    y_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
        "    mean_auprc = average_precision_score(y_bin, y_prob, average=\"macro\")\n",
        "    far = false_alarm_rate(y_test, y_prob, test_encounter_ids, threshold=FAR_THRESHOLD)\n",
        "\n",
        "    trial.set_user_attr(\"mean_auprc\", mean_auprc)\n",
        "    trial.set_user_attr(\"far\", far)\n",
        "    trial.set_user_attr(\"best_iteration\", model.best_iteration)\n",
        "    return mean_auprc, far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1: Exploring hyperparameters on stratified sample (with pruning)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee4f273c819d46c88ac6ed195fac2c28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m[W 2026-02-22 18:24:36,926]\u001b[0m Trial 0 failed with parameters: {'num_leaves': 220, 'learning_rate': 0.049865595701212934, 'feature_fraction': 0.7157682564435697, 'bagging_fraction': 0.7157440438193362, 'bagging_freq': 3, 'min_child_samples': 296, 'reg_alpha': 5.087945070261666, 'reg_lambda': 0.10026475607295682, 'max_depth': 9} because of the following error: RuntimeError('A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.').\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/jackshee/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 206, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/var/folders/xj/ny4zmnqd609bv2rpjzzr11rm0000gn/T/ipykernel_16049/717579126.py\", line 16, in <lambda>\n",
            "    lambda t: objective(t, X_tune, y_tune, w_tune),\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/folders/xj/ny4zmnqd609bv2rpjzzr11rm0000gn/T/ipykernel_16049/1438042213.py\", line 27, in objective\n",
            "    model = lgb.train(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/Users/jackshee/Projects/Medhack/.venv/lib/python3.11/site-packages/lightgbm/engine.py\", line 332, in train\n",
            "    cb(\n",
            "  File \"/Users/jackshee/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna_integration/lightgbm/lightgbm.py\", line 129, in __call__\n",
            "    if self._trial.study.direction != optuna.study.StudyDirection.MINIMIZE:\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jackshee/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/study.py\", line 192, in direction\n",
            "    raise RuntimeError(\n",
            "RuntimeError: A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.\n",
            "\u001b[33m[W 2026-02-22 18:24:36,936]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPhase 1: Exploring hyperparameters on stratified sample (with pruning)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m study = optuna.create_study(\n\u001b[32m     11\u001b[39m     directions=[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m     study_name=\u001b[33m\"\u001b[39m\u001b[33mlgbm_medhack_phase1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     pruner=pruner,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_tune\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS_PHASE1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Phase 1 Pareto Front (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study.best_trials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study.best_trials:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPhase 1: Exploring hyperparameters on stratified sample (with pruning)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m study = optuna.create_study(\n\u001b[32m     11\u001b[39m     directions=[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m     study_name=\u001b[33m\"\u001b[39m\u001b[33mlgbm_medhack_phase1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     pruner=pruner,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m study.optimize(\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_tune\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     17\u001b[39m     n_trials=N_TRIALS_PHASE1,\n\u001b[32m     18\u001b[39m     show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Phase 1 Pareto Front (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study.best_trials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study.best_trials:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, X_tr, y_tr, w_tr)\u001b[39m\n\u001b[32m     24\u001b[39m dval = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n\u001b[32m     26\u001b[39m pruning_callback = LightGBMPruningCallback(trial, \u001b[33m\"\u001b[39m\u001b[33mmulti_logloss\u001b[39m\u001b[33m\"\u001b[39m, valid_name=\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Slightly fewer for Phase 1; early stopping/pruning handles rest\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m y_prob = model.predict(X_test)\n\u001b[32m     40\u001b[39m y_bin = label_binarize(y_test, classes=[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/lightgbm/engine.py:332\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCallbackEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m                \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m                \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbegin_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m                \u001b[49m\u001b[43mend_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m                \u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m callback.EarlyStopException \u001b[38;5;28;01mas\u001b[39;00m earlyStopException:\n\u001b[32m    343\u001b[39m     booster.best_iteration = earlyStopException.best_iteration + \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna_integration/lightgbm/lightgbm.py:129\u001b[39m, in \u001b[36mLightGBMPruningCallback.__call__\u001b[39m\u001b[34m(self, env)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    124\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe intermediate values are inconsistent with the objective values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min terms of study directions. Please specify a metric to be minimized \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor LightGBMPruningCallback.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m         )\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_trial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdirection\u001b[49m != optuna.study.StudyDirection.MINIMIZE:\n\u001b[32m    130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe intermediate values are inconsistent with the objective values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min terms of study directions. Please specify a metric to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmaximized for LightGBMPruningCallback.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m._trial.report(current_score, step=env.iteration)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Medhack/.venv/lib/python3.11/site-packages/optuna/study/study.py:192\u001b[39m, in \u001b[36mStudy.direction\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the direction of the study.\u001b[39;00m\n\u001b[32m    180\u001b[39m \n\u001b[32m    181\u001b[39m \u001b[33;03m.. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    193\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single direction cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    194\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.directions to retrieve a list containing all directions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m     )\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.directions[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mRuntimeError\u001b[39m: A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions."
          ]
        }
      ],
      "source": [
        "N_TRIALS_PHASE1 = 60   # More trials OK: Phase 1 is fast (10% data) + pruning\n",
        "N_TOP_PHASE1 = min(N_TOP_PHASE1, 5)  # Configs to carry to Phase 2\n",
        "CONFIG_SAVE_PATH = Path(DATA_DIR) / \"phase1_best_configs.pkl\"\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10, interval_steps=1)\n",
        "\n",
        "# ---------- Phase 1: Fast exploration on stratified sample ----------\n",
        "print(\"Phase 1: Exploring hyperparameters on stratified sample (with pruning)...\")\n",
        "study = optuna.create_study(\n",
        "    directions=[\"maximize\", \"minimize\"],\n",
        "    study_name=\"lgbm_medhack_phase1\",\n",
        "    pruner=pruner,\n",
        ")\n",
        "study.optimize(\n",
        "    lambda t: objective(t, X_tune, y_tune, w_tune),\n",
        "    n_trials=N_TRIALS_PHASE1,\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Phase 1 Pareto Front ({len(study.best_trials)} trials) ---\")\n",
        "if not study.best_trials:\n",
        "    completed = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "    if not completed:\n",
        "        raise RuntimeError(\"No completed trials in Phase 1. Check for errors or increase n_startup_trials.\")\n",
        "    # Fallback: use completed trials sorted by first objective\n",
        "    best_for_phase2 = sorted(completed, key=lambda t: t.values[0] if t.values else 0, reverse=True)[:N_TOP_PHASE1]\n",
        "else:\n",
        "    best_for_phase2 = sorted(study.best_trials, key=lambda x: x.values[0], reverse=True)[:N_TOP_PHASE1]\n",
        "\n",
        "for i, t in enumerate(best_for_phase2):\n",
        "    print(f\"  Trial {t.number}: AUPRC={t.values[0]:.4f}, FAR={t.values[1]:.4f}\")\n",
        "\n",
        "# Save top configs: Pareto trials + their params, sorted by AUPRC (desc)\n",
        "phase1_configs = []\n",
        "for t in best_for_phase2:\n",
        "    phase1_configs.append({\n",
        "        \"params\": t.params.copy(),\n",
        "        \"trial_number\": t.number,\n",
        "        \"phase1_auprc\": t.values[0],\n",
        "        \"phase1_far\": t.values[1],\n",
        "        \"best_iteration\": t.user_attrs.get(\"best_iteration\", 500),\n",
        "    })\n",
        "with open(CONFIG_SAVE_PATH, \"wb\") as f:\n",
        "    pickle.dump(phase1_configs, f)\n",
        "print(f\"\\nSaved {N_TOP_PHASE1} best configs to {CONFIG_SAVE_PATH}\")\n",
        "\n",
        "# ---------- Phase 2: Refine top configs on full (or 50%) data ----------\n",
        "if PHASE2_FULL_DATA or phase2_mask is None:\n",
        "    X_phase2 = X_train\n",
        "    y_phase2 = y_train.values\n",
        "    w_phase2 = sample_weights\n",
        "else:\n",
        "    X_phase2 = X_train[phase2_mask].copy()\n",
        "    y_phase2 = y_train[phase2_mask].values\n",
        "    w_phase2 = sample_weights[phase2_mask.values]\n",
        "n_phase2 = X_phase2.shape[0]\n",
        "print(f\"\\nPhase 2: Evaluating top {N_TOP_PHASE1} configs on {n_phase2:,} rows...\")\n",
        "\n",
        "phase2_results = []\n",
        "for cfg in phase1_configs:\n",
        "    params = cfg[\"params\"].copy()\n",
        "    params.update({\n",
        "        \"objective\": \"multiclass\", \"num_class\": 4, \"metric\": \"multi_logloss\",\n",
        "        \"boosting_type\": \"gbdt\", \"verbosity\": -1, \"n_jobs\": -1, \"seed\": 42,\n",
        "    })\n",
        "    n_rounds = max(cfg[\"best_iteration\"], 500)\n",
        "    dtrain = lgb.Dataset(X_phase2, label=y_phase2, weight=w_phase2)\n",
        "    dval = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
        "    model = lgb.train(\n",
        "        params, dtrain,\n",
        "        num_boost_round=min(n_rounds * 2, 2500),  # Allow some headroom\n",
        "        valid_sets=[dval],\n",
        "        callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)],\n",
        "    )\n",
        "    y_prob = model.predict(X_test)\n",
        "    mean_auprc = average_precision_score(\n",
        "        label_binarize(y_test, classes=[0, 1, 2, 3]), y_prob, average=\"macro\"\n",
        "    )\n",
        "    far = false_alarm_rate(y_test, y_prob, test_encounter_ids, threshold=FAR_THRESHOLD)\n",
        "    phase2_results.append({\n",
        "        \"trial_number\": cfg[\"trial_number\"],\n",
        "        \"params\": params,\n",
        "        \"best_iteration\": model.best_iteration,\n",
        "        \"auprc\": mean_auprc,\n",
        "        \"far\": far,\n",
        "    })\n",
        "    print(f\"  Trial {cfg['trial_number']}: AUPRC={mean_auprc:.4f}, FAR={far:.4f}\")\n",
        "\n",
        "best_phase2 = max(phase2_results, key=lambda r: r[\"auprc\"])\n",
        "best_trial = type(\"BestTrial\", (), {\n",
        "    \"params\": best_phase2[\"params\"],\n",
        "    \"number\": best_phase2[\"trial_number\"],\n",
        "    \"user_attrs\": {\n",
        "        \"mean_auprc\": best_phase2[\"auprc\"],\n",
        "        \"far\": best_phase2[\"far\"],\n",
        "        \"best_iteration\": best_phase2[\"best_iteration\"],\n",
        "    },\n",
        "})()\n",
        "print(f\"\\nSelected (Phase 2 best AUPRC): Trial {best_trial.number}\")\n",
        "print(f\"  Mean AUPRC: {best_trial.user_attrs['mean_auprc']:.4f}\")\n",
        "print(f\"  FAR: {best_trial.user_attrs['far']:.4f}\")\n",
        "print(f\"  Best iteration: {best_trial.user_attrs['best_iteration']}\")\n",
        "print(f\"\\nBest params:\")\n",
        "for k, v in best_trial.params.items():\n",
        "    if k not in (\"objective\", \"num_class\", \"metric\", \"boosting_type\", \"verbosity\", \"n_jobs\", \"seed\"):\n",
        "        print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: visualization (requires plotly)\n",
        "try:\n",
        "    from optuna.visualization import plot_pareto_front, plot_param_importances\n",
        "    fig1 = plot_pareto_front(study, target_names=[\"AUPRC\", \"FAR\"])\n",
        "    fig1.show()\n",
        "    fig2 = plot_param_importances(study, target=lambda t: t.values[0])  # by AUPRC\n",
        "    fig2.show()\n",
        "except Exception as e:\n",
        "    print(f\"Visualization skipped: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Final Model and Save\n",
        "\n",
        "Trains on train set with best params, then saves model and feature columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build final params from selected Pareto-optimal trial\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])\n",
        "best_params = best_trial.params.copy()\n",
        "best_params.update({\n",
        "    \"objective\": \"multiclass\",\n",
        "    \"num_class\": 4,\n",
        "    \"metric\": \"multi_logloss\",\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"verbosity\": -1,\n",
        "    \"n_jobs\": -1,\n",
        "    \"seed\": 42,\n",
        "})\n",
        "\n",
        "best_iteration = best_trial.user_attrs[\"best_iteration\"]\n",
        "best_iteration = max(best_iteration, 500)  # Ensure minimum rounds\n",
        "\n",
        "print(f\"Training final model on train ({best_iteration} rounds)...\")\n",
        "dtrain_full = lgb.Dataset(X_train, label=y_train, weight=sample_weights)\n",
        "final_model = lgb.train(best_params, dtrain_full, num_boost_round=best_iteration)\n",
        "\n",
        "# Save to Drive\n",
        "out_dir = Path(DRIVE_DATA_DIR)\n",
        "with open(out_dir / \"lgb_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(final_model, f)\n",
        "with open(out_dir / \"feature_cols.pkl\", \"wb\") as f:\n",
        "    pickle.dump(feature_cols, f)\n",
        "\n",
        "print(f\"Saved to {out_dir}: lgb_model.pkl, feature_cols.pkl\")\n",
        "\n",
        "# Evaluate on test\n",
        "test_preds = final_model.predict(X_test).argmax(axis=1)\n",
        "test_f1 = f1_score(y_test, test_preds, average=\"macro\")\n",
        "test_auprc = average_precision_score(label_binarize(y_test, classes=[0,1,2,3]), final_model.predict(X_test), average=\"macro\")\n",
        "test_far = false_alarm_rate(y_test, final_model.predict(X_test), test_encounter_ids, threshold=FAR_THRESHOLD)\n",
        "print(f\"\\nTest: Macro F1={test_f1:.4f}, AUPRC={test_auprc:.4f}, FAR={test_far:.4f}\")\n",
        "print(classification_report(y_test, test_preds, target_names=[\"Normal\", \"Warning\", \"Crisis\", \"Death\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Submission\n",
        "\n",
        "Predict on holdout and save `submission.csv` to Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading model and feature columns...\")\n",
        "with open(DATA_DIR / \"lgb_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "with open(DATA_DIR / \"feature_cols.pkl\", \"rb\") as f:\n",
        "    feature_cols = pickle.load(f)\n",
        "\n",
        "for col in feature_cols:\n",
        "    if col not in holdout.columns:\n",
        "        holdout[col] = 0\n",
        "\n",
        "X_holdout = holdout[feature_cols].copy()\n",
        "# Convert datetime to numeric (same as train/test)\n",
        "for col in feature_cols:\n",
        "    if pd.api.types.is_datetime64_any_dtype(X_holdout[col].dtype):\n",
        "        X_holdout[col] = X_holdout[col].astype(\"int64\")\n",
        "print(f\"Holdout shape: {X_holdout.shape}\")\n",
        "\n",
        "proba = model.predict(X_holdout)\n",
        "predictions = proba.argmax(axis=1)\n",
        "\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "for label in sorted(np.unique(predictions)):\n",
        "    count = (predictions == label).sum()\n",
        "    print(f\"  Label {label}: {count:,} ({count/len(predictions)*100:.1f}%)\")\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": np.arange(1, len(predictions) + 1),\n",
        "    \"predicted_label\": predictions,\n",
        "})\n",
        "sub_path = Path(DRIVE_DATA_DIR) / \"submission.csv\"\n",
        "submission.to_csv(sub_path, index=False)\n",
        "print(f\"\\nSaved {sub_path}\")\n",
        "\n",
        "# Verify if sample_submission exists\n",
        "sample_path = DATA_DIR / \"sample_submission.csv\"\n",
        "if sample_path.exists():\n",
        "    sample = pd.read_csv(sample_path)\n",
        "    assert len(submission) == len(sample), f\"Row mismatch: {len(submission)} vs {len(sample)}\"\n",
        "    assert list(submission.columns) == list(sample.columns), \"Column mismatch\"\n",
        "    print(\"Format verified against sample_submission.csv!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download submission to local machine (optional)\n",
        "from google.colab import files\n",
        "files.download(str(Path(DRIVE_DATA_DIR) / \"submission.csv\"))\n",
        "print(\"Downloaded submission.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
