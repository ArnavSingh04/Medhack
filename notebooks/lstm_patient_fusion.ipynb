{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + Patient Features Fusion\n",
    "\n",
    "Implements the dual-branch architecture from `specs/lstm_patient_fusion_spec.md`:\n",
    "- **LSTM branch**: vital sign time series `(batch, 7, 5)` → `(batch, 32)`\n",
    "- **Patient branch**: static demographics `(batch, n_static)` (Tier 1: age, gender, BMI, pain score, race, ethnicity)\n",
    "- **Fusion**: `concat` → Dense(32) → Dense(4, softmax)\n",
    "\n",
    "Evaluated with macro ROC AUC (OVR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# MPS = Apple Silicon GPU, falls back to CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "DATA_DIR   = Path('../data')\n",
    "MODELS_DIR = Path('../models')\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "VITAL_COLS = ['heart_rate', 'systolic_bp', 'diastolic_bp', 'respiratory_rate', 'oxygen_saturation']\n",
    "N_LAGS = 6\n",
    "TRAIN_SAMPLE_SIZE = 500_000\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "# Tier 1 patient features\n",
    "NUMERIC_PATIENT_COLS     = ['age', 'bmi', 'pain_score']\n",
    "CATEGORICAL_PATIENT_COLS = ['race', 'ethnicity']\n",
    "GENDER_COL = 'gender'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Reshape Vital Time Series\n",
    "\n",
    "Reshapes flat lag columns into `(n_samples, 7, 5)`: 7 timesteps (lag6→current), 5 vital channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_lagged_to_sequences(df: pd.DataFrame, vital_cols: list, n_lags: int) -> np.ndarray:\n",
    "    \"\"\"Reshape pre-computed lag columns into (n_samples, timesteps, n_vitals).\n",
    "\n",
    "    Timestep order: lag_n, ..., lag_1, current (oldest → newest).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for col in vital_cols:\n",
    "        lag_cols = [f'{col}_lag{i}' for i in range(n_lags, 0, -1)]\n",
    "        sequences.append(df[lag_cols + [col]].values)\n",
    "    return np.stack(sequences, axis=-1)  # (n_samples, 7, 5)\n",
    "\n",
    "\n",
    "train_raw = pd.read_csv(DATA_DIR / 'train_data_lagged.csv')\n",
    "test_raw  = pd.read_csv(DATA_DIR / 'test_data_lagged.csv')\n",
    "\n",
    "X_ts_train_full = reshape_lagged_to_sequences(train_raw, VITAL_COLS, N_LAGS)\n",
    "y_train_full    = train_raw['label'].values\n",
    "X_ts_test       = reshape_lagged_to_sequences(test_raw,  VITAL_COLS, N_LAGS)\n",
    "y_test          = test_raw['label'].values\n",
    "\n",
    "print(f\"Train sequences: {X_ts_train_full.shape}\")\n",
    "print(f\"Test  sequences: {X_ts_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Patient Features\n",
    "\n",
    "**Tier 1** features per spec:\n",
    "- `age`, `bmi`, `pain_score` — standardized, median-imputed\n",
    "- `gender` — binary encoded (M=0, F=1), missing→-1\n",
    "- `race`, `ethnicity` — one-hot encoded (fit on train only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(DATA_DIR / 'patients.csv')\n",
    "print(f\"patients.csv shape: {patients.shape}\")\n",
    "print(patients.head(3))\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(patients.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(series: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Map gender to binary: M→0, F→1, missing→-1.\"\"\"\n",
    "    mapping = {'M': 0, 'Male': 0, 'male': 0, 'F': 1, 'Female': 1, 'female': 1}\n",
    "    return series.map(mapping).fillna(-1).astype(float).values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "class PatientFeaturePreprocessor:\n",
    "    \"\"\"Fit on train patients; transform any split. Produces a dense float32 array.\"\"\"\n",
    "\n",
    "    def __init__(self, numeric_cols=NUMERIC_PATIENT_COLS,\n",
    "                 categorical_cols=CATEGORICAL_PATIENT_COLS, gender_col=GENDER_COL):\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.gender_col = gender_col\n",
    "        self.num_scaler = StandardScaler()\n",
    "        self.cat_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        self._num_medians: dict = {}\n",
    "        self._cat_cols_present: list = []\n",
    "\n",
    "    def fit(self, patients_df: pd.DataFrame) -> 'PatientFeaturePreprocessor':\n",
    "        for col in self.numeric_cols:\n",
    "            self._num_medians[col] = patients_df[col].median() if col in patients_df.columns else 0.0\n",
    "        self.num_scaler.fit(self._impute_numeric(patients_df))\n",
    "\n",
    "        self._cat_cols_present = [c for c in self.categorical_cols if c in patients_df.columns]\n",
    "        if self._cat_cols_present:\n",
    "            self.cat_encoder.fit(patients_df[self._cat_cols_present].fillna('unknown').astype(str))\n",
    "        return self\n",
    "\n",
    "    def _impute_numeric(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        parts = []\n",
    "        for col in self.numeric_cols:\n",
    "            vals = df[col].fillna(self._num_medians[col]).values if col in df.columns \\\n",
    "                   else np.full(len(df), self._num_medians.get(col, 0.0))\n",
    "            parts.append(vals.reshape(-1, 1))\n",
    "        return np.hstack(parts).astype(float)\n",
    "\n",
    "    def transform(self, patients_df: pd.DataFrame) -> np.ndarray:\n",
    "        parts = [self.num_scaler.transform(self._impute_numeric(patients_df))]\n",
    "        if self.gender_col in patients_df.columns:\n",
    "            parts.append(encode_gender(patients_df[self.gender_col]))\n",
    "        else:\n",
    "            parts.append(np.full((len(patients_df), 1), -1.0))\n",
    "        if self._cat_cols_present:\n",
    "            parts.append(self.cat_encoder.transform(\n",
    "                patients_df[self._cat_cols_present].fillna('unknown').astype(str)\n",
    "            ))\n",
    "        return np.hstack(parts).astype(np.float32)\n",
    "\n",
    "\n",
    "train_patients = patients[patients['encounter_id'].isin(train_raw['encounter_id'])]\n",
    "pat_preprocessor = PatientFeaturePreprocessor()\n",
    "pat_preprocessor.fit(train_patients)\n",
    "n_static = pat_preprocessor.transform(train_patients.head(1)).shape[1]\n",
    "print(f\"n_static features: {n_static}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join Patient Features to Lagged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_static_features(lagged_df: pd.DataFrame, patients_df: pd.DataFrame,\n",
    "                           preprocessor: PatientFeaturePreprocessor) -> np.ndarray:\n",
    "    \"\"\"Left-join patients to lagged rows on encounter_id, then transform.\"\"\"\n",
    "    pat_cols = ['encounter_id'] + [\n",
    "        c for c in preprocessor.numeric_cols + preprocessor.categorical_cols + [preprocessor.gender_col]\n",
    "        if c in patients_df.columns\n",
    "    ]\n",
    "    merged = lagged_df[['encounter_id']].merge(patients_df[pat_cols], on='encounter_id', how='left')\n",
    "    return preprocessor.transform(merged)\n",
    "\n",
    "\n",
    "X_static_train_full = build_static_features(train_raw, patients, pat_preprocessor)\n",
    "X_static_test       = build_static_features(test_raw,  patients, pat_preprocessor)\n",
    "\n",
    "print(f\"Static train: {X_static_train_full.shape}\")\n",
    "print(f\"Static test:  {X_static_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stratified Sample + Standardize Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, train_size=TRAIN_SAMPLE_SIZE, random_state=RANDOM_STATE)\n",
    "idx, _ = next(splitter.split(X_ts_train_full, y_train_full))\n",
    "\n",
    "X_ts_train   = X_ts_train_full[idx]\n",
    "X_stat_train = X_static_train_full[idx]\n",
    "y_train      = y_train_full[idx]\n",
    "\n",
    "print(f\"Sampled train: {X_ts_train.shape}, static: {X_stat_train.shape}\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_timesteps, n_vitals = X_ts_train.shape\n",
    "ts_scaler = StandardScaler()\n",
    "ts_scaler.fit(X_ts_train.reshape(-1, n_vitals))\n",
    "\n",
    "X_ts_train_sc = ts_scaler.transform(X_ts_train.reshape(-1, n_vitals)).reshape(n_samples, n_timesteps, n_vitals)\n",
    "X_ts_test_sc  = ts_scaler.transform(X_ts_test.reshape(-1, n_vitals)).reshape(X_ts_test.shape[0], n_timesteps, n_vitals)\n",
    "\n",
    "print(f\"Scaled train: {X_ts_train_sc.shape}, test: {X_ts_test_sc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Fusion Model\n",
    "\n",
    "```\n",
    "vitals (7,5) → LSTM(64)→Dropout→LSTM(32)→Dropout ─┐\n",
    "                                                    concat → Linear(32,relu)→Dropout→Linear(4)\n",
    "static (n,)  ─────────────────────────────────────-┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMFusionModel(nn.Module):\n",
    "    def __init__(self, n_vitals: int, n_static: int, n_classes: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(n_vitals, 64, batch_first=True)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        self.lstm2 = nn.LSTM(64, 32, batch_first=True)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 + n_static, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ts: torch.Tensor, x_static: torch.Tensor) -> torch.Tensor:\n",
    "        out, _ = self.lstm1(x_ts)\n",
    "        out = self.drop1(out)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]  # last timestep → (batch, 32)\n",
    "        out = self.drop2(out)\n",
    "        fused = torch.cat([out, x_static], dim=1)\n",
    "        return self.classifier(fused)  # logits (batch, n_classes)\n",
    "\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "model = LSTMFusionModel(n_vitals, n_static, n_classes).to(DEVICE)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTrainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse-frequency class weights for imbalanced labels\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights_np = len(y_train) / (n_classes * class_counts)\n",
    "class_weights_t = torch.tensor(class_weights_np, dtype=torch.float32).to(DEVICE)\n",
    "print(f\"Class weights: {dict(enumerate(class_weights_np.round(3)))}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_t)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2, min_lr=1e-5)\n",
    "\n",
    "# Build DataLoaders\n",
    "def make_loader(X_ts, X_stat, y, batch_size=512, shuffle=True):\n",
    "    ds = TensorDataset(\n",
    "        torch.tensor(X_ts,   dtype=torch.float32),\n",
    "        torch.tensor(X_stat, dtype=torch.float32),\n",
    "        torch.tensor(y,      dtype=torch.long),\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# 90/10 train/val split\n",
    "val_split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_STATE)\n",
    "tr_idx, val_idx = next(val_split.split(X_ts_train_sc, y_train))\n",
    "\n",
    "train_loader = make_loader(X_ts_train_sc[tr_idx],  X_stat_train[tr_idx],  y_train[tr_idx])\n",
    "val_loader   = make_loader(X_ts_train_sc[val_idx], X_stat_train[val_idx], y_train[val_idx], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "PATIENCE = 3\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_state = None\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    train_loss = train_correct = train_total = 0\n",
    "    for X_ts_b, X_st_b, y_b in train_loader:\n",
    "        X_ts_b, X_st_b, y_b = X_ts_b.to(DEVICE), X_st_b.to(DEVICE), y_b.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_ts_b, X_st_b)\n",
    "        loss = criterion(logits, y_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss    += loss.item() * len(y_b)\n",
    "        train_correct += (logits.argmax(1) == y_b).sum().item()\n",
    "        train_total   += len(y_b)\n",
    "\n",
    "    # --- Validate ---\n",
    "    model.eval()\n",
    "    val_loss = val_correct = val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_ts_b, X_st_b, y_b in val_loader:\n",
    "            X_ts_b, X_st_b, y_b = X_ts_b.to(DEVICE), X_st_b.to(DEVICE), y_b.to(DEVICE)\n",
    "            logits = model(X_ts_b, X_st_b)\n",
    "            val_loss    += criterion(logits, y_b).item() * len(y_b)\n",
    "            val_correct += (logits.argmax(1) == y_b).sum().item()\n",
    "            val_total   += len(y_b)\n",
    "\n",
    "    t_loss = train_loss / train_total\n",
    "    v_loss = val_loss   / val_total\n",
    "    t_acc  = train_correct / train_total\n",
    "    v_acc  = val_correct   / val_total\n",
    "    history['train_loss'].append(t_loss)\n",
    "    history['val_loss'].append(v_loss)\n",
    "    history['train_acc'].append(t_acc)\n",
    "    history['val_acc'].append(v_acc)\n",
    "\n",
    "    scheduler.step(v_loss)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch:02d}  train_loss={t_loss:.4f}  val_loss={v_loss:.4f}  \"\n",
    "          f\"train_acc={t_acc:.4f}  val_acc={v_acc:.4f}  lr={lr:.2e}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if v_loss < best_val_loss:\n",
    "        best_val_loss = v_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_state)\n",
    "torch.save(model.state_dict(), MODELS_DIR / 'lstm_patient_fusion.pt')\n",
    "print(f\"\\nBest model saved to {MODELS_DIR / 'lstm_patient_fusion.pt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(history['train_loss'], label='train')\n",
    "axes[0].plot(history['val_loss'],   label='val')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='train')\n",
    "axes[1].plot(history['val_acc'],   label='val')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, X_ts_sc, X_stat, batch_size=512):\n",
    "    \"\"\"Run inference and return softmax probabilities as numpy array.\"\"\"\n",
    "    model.eval()\n",
    "    loader = make_loader(X_ts_sc, X_stat, np.zeros(len(X_ts_sc), dtype=np.int64),\n",
    "                         batch_size=batch_size, shuffle=False)\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for X_ts_b, X_st_b, _ in loader:\n",
    "            logits = model(X_ts_b.to(DEVICE), X_st_b.to(DEVICE))\n",
    "            probs.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
    "    return np.vstack(probs)\n",
    "\n",
    "\n",
    "y_proba = predict_proba(model, X_ts_test_sc, X_static_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')\n",
    "print(f\"Test ROC AUC (macro, OVR): {roc_auc:.4f}\")\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))\n",
    "for cls in range(n_classes):\n",
    "    auc_cls = roc_auc_score(y_test_bin[:, cls], y_proba[:, cls])\n",
    "    print(f\"  Class {cls} AUC: {auc_cls:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Holdout Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_raw = pd.read_csv(DATA_DIR / 'holdout_data_lagged.csv')\n",
    "\n",
    "X_ts_holdout    = reshape_lagged_to_sequences(holdout_raw, VITAL_COLS, N_LAGS)\n",
    "X_ts_holdout_sc = ts_scaler.transform(\n",
    "    X_ts_holdout.reshape(-1, n_vitals)\n",
    ").reshape(X_ts_holdout.shape[0], n_timesteps, n_vitals)\n",
    "X_static_holdout = build_static_features(holdout_raw, patients, pat_preprocessor)\n",
    "\n",
    "y_holdout_proba = predict_proba(model, X_ts_holdout_sc, X_static_holdout)\n",
    "print(f\"Holdout predictions shape: {y_holdout_proba.shape}\")\n",
    "\n",
    "if 'label' in holdout_raw.columns:\n",
    "    roc_auc_holdout = roc_auc_score(\n",
    "        holdout_raw['label'], y_holdout_proba, multi_class='ovr', average='macro'\n",
    "    )\n",
    "    print(f\"Holdout ROC AUC (macro, OVR): {roc_auc_holdout:.4f}\")\n",
    "else:\n",
    "    print(\"Holdout has no labels; predictions ready for submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_holdout_proba, columns=[f'label_{i}' for i in range(n_classes)])\n",
    "if 'encounter_id' in holdout_raw.columns:\n",
    "    submission.insert(0, 'encounter_id', holdout_raw['encounter_id'].values)\n",
    "\n",
    "out_path = DATA_DIR / 'lstm_fusion_holdout_predictions.csv'\n",
    "submission.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
